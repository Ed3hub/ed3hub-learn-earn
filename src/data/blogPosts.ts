export interface BlogPost {
  id: number;
  title: string;
  excerpt: string;
  category: string;
  date: string;
  readTime: string;
  tags: string[];
  slug: string;
  author?: string;
  keywords?: string;
  content?: {
    introduction: string;
    sections: Array<{
      title: string;
      content: string;
    }>;
  };
}

export const blogPosts: BlogPost[] = [
  {
    id: 1,
    title: "Getting Started with Web3 Development: A Comprehensive Guide",
    excerpt: "Learn the fundamentals of Web3 development, from blockchain basics to smart contract deployment. Perfect for beginners looking to enter the decentralized web.",
    category: "Web3",
    date: "2025-10-25",
    readTime: "8 min read",
    tags: ["Blockchain", "Smart Contracts", "Ethereum"],
    slug: "getting-started-with-web3-development",
    author: "Ed3hub Team",
    keywords: "Web3 development, blockchain, smart contracts, decentralized apps, dApp development, Ethereum, Solidity, Ed3hub"
  },
  {
    id: 2,
    title: "Data Engineering Best Practices for 2025",
    excerpt: "Explore modern data engineering practices, including data pipeline optimization, cloud-native architectures, and real-time data processing strategies.",
    category: "Data Engineering",
    date: "2025-10-25",
    readTime: "9 min read",
    tags: ["Big Data", "ETL", "Cloud Computing", "Data Pipelines", "AI Infrastructure"],
    slug: "data-engineering-best-practices-2025",
    author: "Ed3hub Team",
    keywords: "data engineering, best practices 2025, data pipelines, ETL, data governance, AI data infrastructure, modern data stack, Ed3hub",
    content: {
      introduction: "As we step deeper into the era of AI-driven innovation, data engineering has become one of the most critical disciplines in technology. In 2025, data engineering isn't just about moving data from point A to point B â€” it's about building intelligent, scalable, and ethical data systems that fuel analytics, machine learning, and real-time decision-making. This guide explores the top data engineering best practices for 2025 â€” from modern tools and architectures to governance, automation, and AI integration.",
      sections: [
        {
          title: "What Is Data Engineering?",
          content: "Data engineering is the process of designing, building, and maintaining systems that collect, process, and store data for analysis and decision-making.\n\nIn today's data-driven world, engineers are responsible for ensuring data is:\n\nâ€¢ Accurate\nâ€¢ Accessible\nâ€¢ Secure\nâ€¢ Ready for AI and analytics\n\nModern data engineering blends software engineering, data architecture, and DevOps to deliver reliable pipelines and infrastructures."
        },
        {
          title: "The Evolution of Data Engineering",
          content: "table:evolution"
        },
        {
          title: "Top Data Engineering Best Practices for 2025",
          content: "1. **Design for Scalability and Real-Time Processing**: Batch pipelines are no longer enough. Adopt event-driven architectures and streaming frameworks like Apache Kafka, Apache Flink, Snowpipe Streaming, and Databricks Delta Live Tables. This ensures that your data systems can scale dynamically as data volume and velocity grow.\n\n2. **Automate ETL/ELT with Modern Tools**: In 2025, manual data pipeline management is outdated. Use automation tools such as Airbyte/Fivetran for ingestion, dbt for transformation, and Dagster/Airflow for orchestration. Automation reduces human error and allows teams to focus on optimization and analysis.\n\n3. **Prioritize Data Governance and Compliance**: With global data privacy regulations (like GDPR, CCPA, and AI Act) expanding, governance must be built in â€” not bolted on. Best practices include defining clear data ownership and lineage, implementing access controls and audit trails, and using metadata management tools like Collibra or Atlan. Governance ensures trust and compliance across the data ecosystem.\n\n4. **Embrace Data Mesh Principles**: Centralized monolithic architectures are being replaced by data mesh â€” a decentralized approach where teams own their data domains. Core principles include data as a product, domain-oriented ownership, self-serve data infrastructure, and federated governance. By applying data mesh, large organizations can scale their data culture efficiently.\n\n5. **Integrate AI and Machine Learning Pipelines**: Data engineering now intersects directly with MLOps and LLMOps. In 2025, data engineers design feature stores for ML, pipelines feed real-time AI models, and LLMs are trained with curated, governed datasets. Key tools: Feast, Vertex AI, MLflow, LangChain, LlamaIndex.\n\n6. **Implement Data Observability**: Proactive monitoring is vital. Tools like Monte Carlo, Bigeye, and Soda detect anomalies, missing data, or schema drifts before they affect production. Observability provides visibility across data freshness, volume, schema, and lineage â€” ensuring trust in analytics and AI results.\n\n7. **Optimize for Cost and Sustainability**: Cloud cost overruns are one of the biggest challenges for modern data teams. Use cost monitoring tools like Finout or CloudZero, data lifecycle management (automated archiving, compression), and serverless and autoscaling compute (e.g., BigQuery, Snowflake, AWS Athena). In 2025, sustainability and efficiency are strategic priorities.\n\n8. **Document and Share Knowledge**: Documentation isn't optional â€” it's a competitive advantage. Use tools like Notion, Confluence, or DataHub to centralize pipeline diagrams, schema definitions, data contracts, and API documentation. This improves onboarding, collaboration, and reduces \"tribal knowledge.\"\n\n9. **Adopt a Security-First Mindset**: Data breaches can destroy trust and value. Follow zero-trust principles: encrypt data at rest and in transit, implement IAM and RBAC consistently, monitor for unusual access patterns, and rotate credentials regularly. AI security also requires red-teaming and model-level access controls.\n\n10. **Continuously Learn and Upskill**: The data engineering ecosystem evolves rapidly. Stay current with open-source releases, Ed3hub's Data Engineering courses, and industry newsletters (e.g., DataTalks, dbt Roundup)."
        },
        {
          title: "Example Modern Data Stack (2025)",
          content: "table:modern-stack"
        },
        {
          title: "Learn Data Engineering with Ed3hub",
          content: "At Ed3hub, you can learn how to build efficient, secure, and modern data pipelines from industry experts.\n\nðŸ’¡ Our upcoming courses cover:\n\nâ€¢ ETL & ELT design\nâ€¢ Modern Data Stack implementation\nâ€¢ Data governance and AI ethics\nâ€¢ Building real-time analytics pipelines\n\nðŸ‘‰ Start learning today at ed3hub.com â€” and earn while you learn."
        }
      ]
    }
  },
  {
    id: 3,
    title: "Cybersecurity Threats Every Developer Should Know (2025 Edition)",
    excerpt: "Stay ahead of 2025's biggest cybersecurity threats. Learn how developers can protect their code, APIs, and cloud systems from modern attacks.",
    category: "Cybersecurity",
    date: "2025-10-25",
    readTime: "12 min read",
    tags: ["Security", "Encryption", "Web Security", "API Security", "Cloud Security"],
    slug: "cybersecurity-threats-every-developer-should-know-2025",
    author: "Ed3hub Team",
    keywords: "cybersecurity for developers, developer security best practices, 2025 cybersecurity threats, secure coding, AI-powered malware, API security, cloud security",
    content: {
      introduction: "If you write code, you're already on the frontlines of cybersecurity, whether you realize it or not. Every line of code you ship can either fortify your product or open a new attack surface.\n\nThe truth? Cyber threats have evolved faster than ever. And in 2025, the cost of ignoring them isn't just a bug: it's brand damage, data loss, and broken trust.\n\nSo, let's break down the most critical cybersecurity threats every developer should know and how to stay one step ahead.",
      sections: [
        {
          title: "1. Supply Chain Attacks: When Your Dependencies Betray You",
          content: "Modern apps depend on thousands of third-party packages. But what happens when one of those packages gets compromised?\n\nThat's a **supply chain attack**: when hackers inject malicious code into trusted dependencies. The scary part? You might be installing the threat yourself without even knowing it.\n\n**What to Do:**\n\nâ€¢ Use verified packages only and check their digital signatures\nâ€¢ Regularly audit dependencies with tools like npm audit, Dependabot, or Snyk\nâ€¢ Lock versions to prevent automatic updates from introducing malicious code\n\n**Pro tip:** Treat dependencies like strangers. Trust only after you verify."
        },
        {
          title: "2. Social Engineering & Phishing 2.0",
          content: "Hackers no longer just brute-force their way in; they trick you into opening the door. From fake GitHub login pages to AI-generated emails mimicking your CTO, social engineering is getting eerily realistic.\n\n**What to Do:**\n\nâ€¢ Enable multi-factor authentication (MFA) everywhere\nâ€¢ Double-check URLs and email domains before logging in\nâ€¢ Educate your team: cybersecurity is everyone's job, not just IT's\n\n*\"The weakest link in any system is still the human behind the keyboard.\"*"
        },
        {
          title: "3. AI-Powered Malware",
          content: "AI isn't just helping developers; it's also helping hackers. In 2025, we're seeing AI-written malware that learns, adapts, and hides itself better than ever.\n\nThese intelligent threats can bypass traditional firewalls and antivirus by constantly rewriting their own signatures.\n\n**What to Do:**\n\nâ€¢ Monitor network behavior, not just known signatures\nâ€¢ Use AI-driven security tools that detect anomalies instead of known patterns\nâ€¢ Keep your libraries and frameworks updated to patch known exploits"
        },
        {
          title: "4. Cloud Misconfigurations",
          content: "Moving to the cloud doesn't mean your data is automatically safe. A single misconfigured bucket or leaked API key can expose everything.\n\n**What to Do:**\n\nâ€¢ Always apply least privilege access: give only the permissions needed\nâ€¢ Rotate API keys and credentials regularly\nâ€¢ Use tools like AWS Config, Azure Policy, or GCP Security Command Center for constant auditing\n\n**Over 80% of cloud breaches in 2024 were caused by human misconfiguration, not sophisticated hacks.**"
        },
        {
          title: "5. API Exploits & Data Leaks",
          content: "APIs are the new attack surface. If your endpoints expose too much data or lack proper authentication, you're practically handing out keys to your system.\n\n**What to Do:**\n\nâ€¢ Implement rate limiting, authentication, and input validation\nâ€¢ Never expose sensitive data in error messages or query responses\nâ€¢ Use API gateways and monitoring tools to spot unusual behavior early"
        },
        {
          title: "6. Zero-Day Vulnerabilities",
          content: "Zero-day exploits are like landmines: they strike before you even know they exist. Hackers exploit unknown vulnerabilities in your frameworks or libraries before patches are released.\n\n**What to Do:**\n\nâ€¢ Follow trusted cybersecurity feeds and patch systems quickly\nâ€¢ Run bug bounty programs or use platforms like HackerOne to crowdsource testing\nâ€¢ Layer your security and don't rely on a single point of defense"
        },
        {
          title: "7. Insider Threats",
          content: "Not every threat comes from the outside. Disgruntled employees, careless contractors, or even overly curious teammates can cause massive security breaches.\n\n**What to Do:**\n\nâ€¢ Restrict data access to \"need-to-know\" only\nâ€¢ Implement role-based access control (RBAC)\nâ€¢ Log and monitor user actions in critical systems"
        },
        {
          title: "Final Thought from Ed3hub",
          content: "Cybersecurity isn't just a security team's responsibility: it's part of modern software craftsmanship. As developers, our job is to write code that doesn't just run, but protects.\n\n**Start with these principles:**\n\nâ€¢ Think security-first in every feature\nâ€¢ Audit dependencies and code regularly\nâ€¢ Educate your team and automate what you can\n\nBecause in 2025, the question isn't if your system will be targeted: it's how ready you'll be when it happens.\n\nAt Ed3hub, we believe developers should build with confidence, not fear. That's why we're helping creators and learners master both development and digital safety in the Web3 era.\n\n**Stay smart. Stay secure.**\n\nYour code is your castle. Guard it well.\n\nLearn more about secure development practices at **ed3hub.com** and earn while you learn."
        }
      ]
    }
  },
  {
    id: 4,
    title: "Machine Learning Model Deployment: From Training to Production",
    excerpt: "You've trained your machine learning model. It's accurate, it performs beautifully on your local machineâ€¦ But now comes the real challenge: getting it into production. Learn how to make your model accessible, scalable, and reliable for real users.",
    category: "Machine Learning",
    date: "2025-10-25",
    readTime: "12 min read",
    tags: ["MLOps", "AI", "Production", "Cloud Deployment", "Model Monitoring", "CI/CD"],
    slug: "machine-learning-model-deployment-from-training-to-production",
    author: "Ed3hub Team",
    keywords: "machine learning model deployment, ML model production, MLOps guide, AI deployment best practices, cloud model deployment, deploy ML models with Flask, model versioning, machine learning CI/CD, model monitoring, model drift",
    content: {
      introduction: "You've trained your machine learning model. It's accurate, it performs beautifully on your local machineâ€¦ But now comes the real challenge: getting it into production.\n\nIn other words: How do you make your model accessible, scalable, and reliable enough for real users, not just Jupyter notebooks?\n\nWelcome to the world of Machine Learning Deployment: the bridge between data science and real-world impact.\n\nIn this guide, we'll break down everything you need to know to go from training to production like a pro.",
      sections: [
        {
          title: "Step 1: Model Training â€” The Foundation",
          content: "Everything begins here. Model training is where you teach your algorithm to recognize patterns from data.\n\nYou typically:\n\nâ€¢ Gather and clean data\nâ€¢ Split it into training, validation, and test sets\nâ€¢ Select and train a model (say, XGBoost, BERT, or a neural network)\nâ€¢ Evaluate metrics like accuracy, F1-score, or RMSE\n\n**Pro Tip:** Always save your model after training using a framework's serializer:\n\nâ€¢ `joblib` or `pickle` for Scikit-Learn\nâ€¢ `torch.save()` for PyTorch\nâ€¢ `model.save()` for TensorFlow/Keras\n\nThis makes it portable for deployment later."
        },
        {
          title: "Step 2: Model Packaging â€” Preparing for the Real World",
          content: "Before deploying, you need to package your model so it can run consistently on other machines.\n\nThat means:\n\nâ€¢ Freezing dependencies (use `requirements.txt` or `environment.yaml`)\nâ€¢ Storing model weights, metadata, and version info\nâ€¢ Optionally, wrapping your model in a Python API using Flask or FastAPI\n\n**Example:**\n\n```python\nfrom fastapi import FastAPI\nimport joblib\n\napp = FastAPI()\nmodel = joblib.load(\"model.pkl\")\n\n@app.post(\"/predict\")\ndef predict(data: dict):\n    prediction = model.predict([data['features']])\n    return {\"prediction\": prediction.tolist()}\n```\n\nNow your model can be accessed through an API endpoint: ready for real-time predictions."
        },
        {
          title: "Step 3: Deployment Options â€” Choose Your Environment",
          content: "You've got several paths for getting your model live, depending on scale, budget, and performance needs.\n\n**1. Local or On-Premise Deployment**\n\nPerfect for small internal use or testing environments. Use Docker to containerize your model for consistency.\n\n```bash\ndocker build -t ml-model .\ndocker run -p 8000:8000 ml-model\n```\n\n**2. Cloud Deployment**\n\nFor scalability and automation. Popular platforms include:\n\nâ€¢ AWS SageMaker\nâ€¢ Google Vertex AI\nâ€¢ Azure ML Studio\nâ€¢ Hugging Face Inference API\n\nThese handle everything: scaling, monitoring, versioning, and updates.\n\n**3. Edge Deployment**\n\nFor models running on IoT or mobile devices (e.g., TensorFlow Lite, CoreML). Best when low latency or offline inference is needed."
        },
        {
          title: "Step 4: Monitoring and Model Drift",
          content: "Once deployed, the job isn't over: it's just beginning. Models degrade over time as data changes: a phenomenon called **model drift**.\n\nTo combat that:\n\nâ€¢ Log predictions and actual outcomes\nâ€¢ Set up dashboards with tools like Prometheus, Grafana, or Weights & Biases\nâ€¢ Retrain your model periodically when accuracy starts dropping\n\n**Pro Tip:** Automate retraining pipelines using MLOps tools like MLflow, Kubeflow, or Airflow."
        },
        {
          title: "Step 5: Versioning and CI/CD for Models",
          content: "Software engineers have CI/CD: ML engineers need it too.\n\n**Use:**\n\nâ€¢ **DVC** (Data Version Control) or **MLflow** to track datasets and models\nâ€¢ **GitHub Actions** or **GitLab CI** to automate deployment each time your model is updated\nâ€¢ **Feature stores** (like Feast) to maintain consistent data across training and inference\n\nThis ensures that every new version of your model is reproducible and safely deployed."
        },
        {
          title: "Step 6: Security, Ethics & Governance",
          content: "Never overlook security. A single exposed model endpoint can leak private data or allow adversarial attacks.\n\nâœ… Use HTTPS and token-based authentication\nâœ… Validate input data before inference\nâœ… Apply rate limiting and logging\nâœ… Consider fairness and bias detection (using tools like IBM AI Fairness 360)\n\nRemember: production ML isn't just about performance: it's about trust and responsibility."
        },
        {
          title: "Wrapping It All Up",
          content: "Deploying a machine learning model isn't just the \"last step\": it's an entire discipline. It blends data science, DevOps, and software engineering into one process we now call **MLOps**.\n\nHere's the quick roadmap to production success:\n\n1. Train and evaluate your model\n2. Package it with dependencies\n3. Deploy it in the right environment\n4. Monitor, retrain, and secure\n\nOnce you master deployment, your models stop being demos: and start driving real impact."
        },
        {
          title: "Final Thought from Ed3hub",
          content: "At Ed3hub, we believe great developers don't just build models: they bring them to life. That's why we're helping learners master MLOps, AI deployment, and scalable systems that power the next era of innovation.\n\nYour model isn't done when it's trained: it's done when it's trusted in production.\n\nLearn more at **ed3hub.com** and earn while you learn."
        }
      ]
    }
  },
  {
    id: 5,
    title: "The Art of Technical Writing: Communicating Complex Ideas Simply",
    excerpt: "Master the art of technical writing in 2025. Learn proven techniques to explain complex ideas simply and create documentation developers actually want to read.",
    category: "Technical Writing",
    date: "2025-10-31",
    readTime: "6 min read",
    tags: ["Documentation", "Writing", "Communication", "Developer Docs", "API Documentation"],
    slug: "art-of-technical-writing",
    author: "Ed3hub",
    keywords: "technical writing, developer documentation, clear writing for developers, API docs, documentation best practices 2025, AI in technical writing",
    content: {
      introduction: "In today's fast-paced tech landscape, communication is just as important as code. You can write the most brilliant algorithm or design the most elegant API â€” but if you can't explain it clearly, your work risks being misunderstood, underused, or ignored.\n\nThat's where technical writing comes in. It bridges the gap between complex technology and human understanding â€” making sure your ideas, products, and systems are accessible to everyone, from developers to end users.",
      sections: [
        {
          title: "What Is Technical Writing?",
          content: "**Technical writing** is the process of translating complex, technical information into simple, structured, and readable content. It's not just about manuals â€” it's about **helping others use, build, and learn faster**.\n\nExamples include:\n\nâ€¢ Developer documentation and SDK guides\nâ€¢ API references and tutorials\nâ€¢ Knowledge base articles\nâ€¢ Whitepapers and product overviews\nâ€¢ Internal engineering wikis\n\nAt its core, technical writing is **about empathy** â€” understanding what your reader knows (and doesn't) and communicating in a way that meets them where they are."
        },
        {
          title: "Why Technical Writing Matters in 2025",
          content: "As AI tools, decentralized apps, and Web3 systems grow more complex, **clear documentation has become a competitive advantage**.\n\n1. **Developers prefer docs over demos.** Most developers want to learn through documentation first before asking questions.\n\n2. **AI tools learn from your docs.** Your well-structured content can literally train AI assistants to answer questions about your platform.\n\n3. **Poor documentation = lost adoption.** Confusing or missing docs are one of the top reasons products fail to attract developers."
        },
        {
          title: "Key Principles of Great Technical Writing",
          content: "**1. Clarity Above All**\n\nWrite as if your reader is intelligent but busy. Avoid jargon when a simpler phrase works just as well.\n\n**Bad:** \"The system leverages multi-threaded asynchronous communication mechanisms.\"\n\n**Better:** \"The system sends and receives messages at the same time using multiple threads.\"\n\n**2. Structure for Scanability**\n\nUse short paragraphs, bullet points, and headings. Developers scan before they read â€” help them find what they need fast.\n\n**3. Show, Don't Tell**\n\nCode snippets, diagrams, and examples explain faster than paragraphs of theory.\n\n**4. Keep the Reader in Mind**\n\nAsk: *Who is this for?* A new user needs \"Getting Started,\" while a senior developer wants deep dives or references.\n\n**5. Iterate Like Code**\n\nDocs should evolve as your product does. Use feedback, versioning, and changelogs to keep them current."
        },
        {
          title: "Tools Every Technical Writer Should Know",
          content: "**Markdown & Docs-as-Code tools:** GitBook, Docusaurus, ReadMe.io\n\n**Diagramming tools:** Mermaid, Excalidraw, Figma\n\n**Grammar checkers:** Grammarly, LanguageTool\n\n**AI Assistants:** ChatGPT or Ed3hub AI Docs Helper for summarizing, clarifying, or generating first drafts"
        },
        {
          title: "How to Simplify Complex Ideas",
          content: "Here's the golden rule: **If you can't explain it simply, you don't understand it well enough.**\n\nUse these techniques:\n\nâ€¢ **Use analogies.** Compare abstract systems to familiar concepts.\nâ€¢ **Chunk information.** Break long processes into smaller steps.\nâ€¢ **Define terms early.** Never assume your reader knows what an SDK or RPC call means.\nâ€¢ **Use visuals.** Flow diagrams and tables make information digestible."
        },
        {
          title: "Example: Turning Complexity into Clarity",
          content: "**Before (too technical):**\n\n\"The protocol establishes bi-directional asynchronous streams via a multiplexed channel, enabling full-duplex message exchange.\"\n\n**After (clear version):**\n\n\"The protocol lets two systems send and receive messages at the same time using one shared connection.\""
        },
        {
          title: "Common Mistakes to Avoid",
          content: "â€¢ **Over-explaining everything.** Clarity isn't verbosity.\nâ€¢ **Skipping context.** Start with the \"why\" before diving into the \"how.\"\nâ€¢ **Ignoring tone.** You can be technical and friendly â€” like you're guiding a teammate, not writing a legal document.\nâ€¢ **No examples.** Examples turn abstract explanations into usable insights."
        },
        {
          title: "Why Developers Love Great Documentation",
          content: "Good documentation:\n\nâ€¢ Saves time and frustration\nâ€¢ Builds trust in your product\nâ€¢ Reduces support tickets\nâ€¢ Helps onboard new developers faster\nâ€¢ Strengthens open-source communities\n\nWhen you write well, you **multiply your impact** â€” your words teach at scale."
        },
        {
          title: "AI & The Future of Technical Writing",
          content: "In 2025, technical writing is evolving with AI:\n\nâ€¢ **AI co-writers** can generate first drafts of docs.\nâ€¢ **AI-powered search** can index your documentation for better support.\nâ€¢ **Structured docs (with schema)** help large models like ChatGPT and Perplexity include your content in their answers â€” turning your docs into knowledge sources.\n\nThis means your writing doesn't just serve readers â€” it also powers the **next generation of AI learning**."
        },
        {
          title: "Final Thoughts",
          content: "Technical writing isn't just about explaining â€” it's about **empowering**. When you make complex things simple, you build bridges between knowledge and innovation.\n\nIf you're ready to master this skill, start small: rewrite one confusing paragraph today into something anyone could understand. That's the real art of technical writing.\n\n**Want to sharpen your documentation and communication skills?** Explore Technical Writing & Communication Courses on Ed3hub and learn how to create documentation developers *love* to read."
        }
      ]
    }
  },
  {
    id: 6,
    title: "Building Scalable Applications with Cloud-Native Architecture",
    excerpt: "Discover how to architect and deploy cloud-native applications that scale effortlessly using containers, microservices, and serverless technologies.",
    category: "Cloud Computing",
    date: "2025-01-18",
    readTime: "11 min read",
    tags: ["Cloud", "DevOps", "Microservices"],
    slug: "cloud-native-architecture"
  },
  {
    id: 7,
    title: "UI/UX Design Principles for Developer-Friendly Interfaces",
    excerpt: "Learn essential UI/UX principles that help create intuitive, accessible, and beautiful user interfaces for modern web applications.",
    category: "UI/UX Design",
    date: "2025-01-15",
    readTime: "9 min read",
    tags: ["Design", "UX", "Accessibility"],
    slug: "uiux-design-principles"
  },
  {
    id: 8,
    title: "Creative Writing for Tech: Telling Stories with Code",
    excerpt: "Explore the intersection of creative writing and technology, and learn how storytelling can enhance your technical content and presentations.",
    category: "Creative Writing",
    date: "2025-01-12",
    readTime: "6 min read",
    tags: ["Writing", "Storytelling", "Content"],
    slug: "creative-writing-for-tech"
  }
];
